{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate accident data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  69\n",
      "Number of accidents:  140016\n",
      "Discarder accidents (because of incompleteness):  489\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "data = {}\n",
    "dataset_path = '../data/2015/'\n",
    "\n",
    "missing = 0\n",
    "# Load Accidents.csv\n",
    "i = 0\n",
    "with open(dataset_path+'Accidents.csv', 'rb') as csvfile:\n",
    "    for line in reader(csvfile, delimiter=','):\n",
    "        if(i==0):\n",
    "            pass\n",
    "        else:\n",
    "            Accident_Index,Location_Easting_OSGR,Location_Northing_OSGR,Longitude,Latitude,Police_Force,Accident_Severity,Number_of_Vehicles,\\\n",
    "            Number_of_Casualties,Date,Day_of_Week,Time,Local_Authority_District,Local_Authority_Highway,_1st_Road_Class,_1st_Road_Number,\\\n",
    "            Road_Type,Speed_limit,Junction_Detail,Junction_Control,_2nd_Road_Class,_2nd_Road_Number,Pedestrian_Crossing_Human_Control,\\\n",
    "            Pedestrian_Crossing_Physical_Facilities,Light_Conditions,Weather_Conditions,Road_Surface_Conditions,Special_Conditions_at_Site,\\\n",
    "            Carriageway_Hazards,Urban_or_Rural_Area,Did_Police_Officer_Attend_Scene_of_Accident,LSOA_of_Accident_Location = line\n",
    "            \n",
    "            if Longitude and Latitude:\n",
    "                data[Accident_Index] = {'Location_Easting_OSGR':Location_Easting_OSGR,'Location_Northing_OSGR':Location_Northing_OSGR,\\\n",
    "                                        'Longitude':Longitude, 'Latitude':Latitude, 'Police_Force':Police_Force, 'Accident_Severity':Accident_Severity,\\\n",
    "                                        'Number_of_Vehicles':Number_of_Vehicles, 'Number_of_Casualties':Number_of_Casualties, 'Date':Date, \\\n",
    "                                        'Day_of_Week':int(Day_of_Week), 'Time':Time, 'Local_Authority_District':Local_Authority_District, \\\n",
    "                                        'Local_Authority_Highway':Local_Authority_Highway, '_1st_Road_Class':_1st_Road_Class, '_1st_Road_Number':_1st_Road_Number,\\\n",
    "                                        'Road_Type':Road_Type, 'Speed_limit':Speed_limit, 'Junction_Detail':Junction_Detail, 'Junction_Control':Junction_Control,\\\n",
    "                                        '_2nd_Road_Class':_2nd_Road_Class, '_2nd_Road_Number':_2nd_Road_Number,\\\n",
    "                                        'Pedestrian_Crossing_Human_Control':Pedestrian_Crossing_Human_Control,\\\n",
    "                                        'Pedestrian_Crossing_Physical_Facilities':Pedestrian_Crossing_Physical_Facilities, 'Light_Conditions':int(Light_Conditions),\\\n",
    "                                        'Weather_Conditions':int(Weather_Conditions), 'Road_Surface_Conditions':Road_Surface_Conditions, \\\n",
    "                                        'Special_Conditions_at_Site':Special_Conditions_at_Site, 'Carriageway_Hazards':Carriageway_Hazards,\\\n",
    "                                        'Urban_or_Rural_Area':Urban_or_Rural_Area, 'Did_Police_Officer_Attend_Scene_of_Accident':Did_Police_Officer_Attend_Scene_of_Accident,\\\n",
    "                                        'LSOA_of_Accident_Location':LSOA_of_Accident_Location}\n",
    "            else:\n",
    "                missing += 1\n",
    "        i+=1\n",
    "\n",
    "# Load Casualties.csv\n",
    "i = 0 \n",
    "with open(dataset_path+'Casualties.csv', 'rb') as csvfile:\n",
    "    for line in reader(csvfile, delimiter=','):\n",
    "        if(i==0):\n",
    "            pass\n",
    "        else:\n",
    "            Accident_Index,Vehicle_Reference,Casualty_Reference,Casualty_Class,Sex_of_Casualty,Age_of_Casualty, \\\n",
    "            Age_Band_of_Casualty,Casualty_Severity,Pedestrian_Location,Pedestrian_Movement,Car_Passenger,Bus_or_Coach_Passenger,\\\n",
    "            Pedestrian_Road_Maintenance_Worker,Casualty_Type,Casualty_Home_Area_Type,Casualty_IMD_Decile = line\n",
    "            \n",
    "            if data.has_key(Accident_Index):\n",
    "                data[Accident_Index].update({'Vehicle_Reference':Vehicle_Reference, 'Casualty_Reference':Casualty_Reference, \\\n",
    "                                             'Casualty_Class':Casualty_Class, 'Sex_of_Casualty':Sex_of_Casualty, \\\n",
    "                                             'Age_of_Casualty':Age_of_Casualty, 'Age_Band_of_Casualty':Age_Band_of_Casualty, \\\n",
    "                                             'Casualty_Severity':int(Casualty_Severity), 'Pedestrian_Location':Pedestrian_Location,\\\n",
    "                                             'Pedestrian_Movement':Pedestrian_Movement, 'Car_Passenger':Car_Passenger, \\\n",
    "                                             'Bus_or_Coach_Passenger':Bus_or_Coach_Passenger, 'Pedestrian_Road_Maintenance_Worker':Pedestrian_Road_Maintenance_Worker,\\\n",
    "                                             'Casualty_Type':Casualty_Type, 'Casualty_Home_Area_Type':Casualty_Home_Area_Type, \\\n",
    "                                             'Casualty_IMD_Decile':Casualty_IMD_Decile})\n",
    "            else:\n",
    "                missing += 1\n",
    "        i+=1\n",
    "\n",
    "        \n",
    "# Load Vehicles.csv\n",
    "i = 0 \n",
    "with open(dataset_path+'Vehicles.csv', 'rb') as csvfile:\n",
    "    for line in reader(csvfile, delimiter=','):\n",
    "        if(i==0):\n",
    "            pass\n",
    "        else:\n",
    "            Accident_Index,Vehicle_Reference,Vehicle_Type,Towing_and_Articulation,Vehicle_Manoeuvre,Vehicle_Location_Restricted_Lane,\\\n",
    "            Junction_Location,Skidding_and_Overturning,Hit_Object_in_Carriageway,Vehicle_Leaving_Carriageway,Hit_Object_off_Carriageway,\\\n",
    "            _1st_Point_of_Impact,Was_Vehicle_Left_Hand_Drive,Journey_Purpose_of_Driver,Sex_of_Driver,Age_of_Driver,Age_Band_of_Driver,\\\n",
    "            Engine_Capacity,Propulsion_Code,Age_of_Vehicle,Driver_IMD_Decile,Driver_Home_Area_Type,Vehicle_IMD_Decile = line\n",
    "\n",
    "            if data.has_key(Accident_Index):\n",
    "                data[Accident_Index].update({'Vehicle_Reference':Vehicle_Reference, 'Vehicle_Type':Vehicle_Type, 'Towing_and_Articulation':Towing_and_Articulation,\\\n",
    "                                             'Vehicle_Manoeuvre':Vehicle_Manoeuvre, 'Vehicle_Location_Restricted_Lane':Vehicle_Location_Restricted_Lane,\\\n",
    "                                             'Junction_Location':Junction_Location, 'Skidding_and_Overturning':Skidding_and_Overturning,\\\n",
    "                                             'Hit_Object_in_Carriageway':Hit_Object_in_Carriageway, 'Vehicle_Leaving_Carriageway':Vehicle_Leaving_Carriageway,\\\n",
    "                                             'Hit_Object_off_Carriageway':Hit_Object_off_Carriageway, '_1st_Point_of_Impact':_1st_Point_of_Impact,\\\n",
    "                                             'Was_Vehicle_Left_Hand_Drive':Was_Vehicle_Left_Hand_Drive, 'Journey_Purpose_of_Driver':Journey_Purpose_of_Driver,\\\n",
    "                                             'Sex_of_Driver':Sex_of_Driver, 'Age_of_Driver':Age_of_Driver, 'Age_Band_of_Driver':Age_Band_of_Driver,\\\n",
    "                                             'Engine_Capacity':Engine_Capacity, 'Propulsion_Code':Propulsion_Code, 'Age_of_Vehicle':Age_of_Vehicle,\\\n",
    "                                             'Driver_IMD_Decile':Driver_IMD_Decile, 'Driver_Home_Area_Type':Driver_Home_Area_Type, 'Vehicle_IMD_Decile':Vehicle_IMD_Decile})\n",
    "            else:\n",
    "                missing += 1\n",
    "        i+=1\n",
    "\n",
    "        \n",
    "# Load MakeModel2015v2.csv\n",
    "i = 0 \n",
    "with open(dataset_path+'MakeModel2015v2.csv', 'rb') as csvfile:\n",
    "    for line in reader(csvfile, delimiter=','):\n",
    "        if(i==0):\n",
    "            pass\n",
    "        else:\n",
    "            Accident_Index,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,_,Brand, Model = line\n",
    "\n",
    "            if data.has_key(Accident_Index):\n",
    "                data[Accident_Index].update({'Brand':Brand, 'Model':Model})\n",
    "            else:\n",
    "                missing += 1\n",
    "        i+=1\n",
    "\n",
    "print \"Number of features: \", len(data[data.keys()[0]].keys())\n",
    "print \"Number of accidents: \", len(data.keys()) \n",
    "print \"Discarder accidents (because of incompleteness): \", missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drivers:  45617349\n",
      "Number of male drivers:  24168223\n",
      "Number of female drivers:  21449126\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "data_drivers = {}\n",
    "dataset_path = '../data/2015/'\n",
    "\n",
    "missing = 0\n",
    "# Load drivers.csv\n",
    "i = 0\n",
    "with open(dataset_path+'drivers.csv', 'rb') as csvfile:\n",
    "    for line in reader(csvfile, delimiter=','):\n",
    "        if(i == 0):\n",
    "            pass\n",
    "        else:\n",
    "            age,_,_,_,_,_,_,licenses,licenses_male,licenses_female = line\n",
    "            data_drivers[int(age)] = {'licenses':int(licenses),'licenses_male':int(licenses_male),'licenses_female':int(licenses_female)}\n",
    "        i+=1\n",
    "\n",
    "\n",
    "drivers_male = sum(data_drivers[i]['licenses_male'] for i in range(17,106))\n",
    "drivers_female = sum(data_drivers[i]['licenses_female'] for i in range(17,106))\n",
    "print \"Number of drivers: \", drivers_male+drivers_female\n",
    "print \"Number of male drivers: \", drivers_male\n",
    "print \"Number of female drivers: \", drivers_female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def map_vehicle_age(v_age):\n",
    "    if v_age == -1:\n",
    "        pass\n",
    "    elif v_age >= 0 and v_age <= 20:\n",
    "        v_age = int(v_age / 2)\n",
    "    else:   \n",
    "        v_age = 10\n",
    "        \n",
    "    return v_age  \n",
    "\n",
    "\n",
    "capacities = [500,1000,1200,1500,1800,2000,2200,2500,2700,3000,3500] \n",
    "def map_capacity(capacity):    \n",
    "    if capacity == -1:\n",
    "        pass\n",
    "    else:\n",
    "        for i in range(len(capacities)):\n",
    "            c = capacities[i]\n",
    "            \n",
    "            if capacity <= c:\n",
    "                capacity = i\n",
    "                break\n",
    "                \n",
    "        if capacity > capacities[-1]:\n",
    "            capacity = len(capacities)\n",
    "            \n",
    "    return capacity\n",
    "\n",
    "\n",
    "step = 3\n",
    "def map_age(age):    \n",
    "    if age < 16:\n",
    "        age_bin = -1\n",
    "    elif age>15 and age < 75:\n",
    "        age_bin = int(age/step)\n",
    "    else:\n",
    "        age_bin = int(75/step)+1\n",
    "        \n",
    "    return age_bin\n",
    "\n",
    "\n",
    "brands = list(set([x['Brand'].strip(\" \").lower() for x in data.itervalues() if x.has_key('Brand')]))\n",
    "def map_brand(brand):\n",
    "    brand = brand.strip(\" \").lower()\n",
    "    return brands.index(brand)\n",
    "\n",
    "car_brands = [map_brand(b)for b in brands]\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy using complete dataset 0.947775767497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "\n",
    "features = ['Age_of_Driver','Engine_Capacity','Brand','Age_of_Vehicle','Vehicle_Type','Sex_of_Driver',\\\n",
    "            'Road_Surface_Conditions','Light_Conditions','Weather_Conditions']\n",
    "response = 'Accident_Severity'\n",
    "\n",
    "brand_one_hot_encoding = False\n",
    "\n",
    "for key,val in data.iteritems():\n",
    "    tmp_X = []\n",
    "    tmp_Y = None\n",
    "    \n",
    "    if val.has_key(response):\n",
    "        tmp_Y = val[response]\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    for feature in features: \n",
    "        if feature == 'Brand' and val.has_key(\"Brand\"):\n",
    "            if brand_one_hot_encoding:                \n",
    "                tmp_X.extend(list(np.eye(np.max(car_brands) + 1)[map_brand('fIAt')]))\n",
    "            else:\n",
    "                tmp_X.append(map_brand(val[feature]))\n",
    "        else:\n",
    "            if val.has_key(feature) and int(val[feature]) != -1:\n",
    "                tmp_X.append(int(val[feature]))\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "    if brand_one_hot_encoding:                \n",
    "        if len(tmp_X) == (len(features)-1+len(brands)): \n",
    "            X[key] = tmp_X\n",
    "            y[key] = tmp_Y\n",
    "\n",
    "            X[key][0] = map_age(X[key][0])\n",
    "            X[key][1] = map_capacity(X[key][1])\n",
    "            X[key][3] = map_vehicle_age(X[key][3])\n",
    "    else:\n",
    "        if len(tmp_X) == len(features):\n",
    "            X[key] = tmp_X\n",
    "            y[key] = tmp_Y\n",
    "\n",
    "            X[key][0] = map_age(X[key][0])\n",
    "            X[key][1] = map_capacity(X[key][1])\n",
    "            X[key][3] = map_vehicle_age(X[key][3])     \n",
    "        \n",
    "parameters = {'n_neighbors':range(4,10), 'p':[1,2], 'weights':['distance']}\n",
    "folds = 5\n",
    "models = GridSearchCV(KNeighborsClassifier(), parameters, n_jobs=-1, cv=folds)\n",
    "models.fit(X=X.values(), y=y.values())\n",
    "        \n",
    "knn = KNeighborsClassifier(n_neighbors=models.best_params_['n_neighbors'], \\\n",
    "                           n_jobs=-1, weights='distance', p=models.best_params_['p'])\n",
    "knn.fit(X.values(), y.values())\n",
    "print \"Average accuracy using complete dataset\", knn.score(X.values(), y.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'n_neighbors': 9, 'weights': 'distance', 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "print 'Best parameters: ', models.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the proportion of each class in the dataset and when doing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of classes in raw data:  [1.3038109186984865, 84.88842939605411, 13.807759685247408]\n",
      "Percentage of classes in predictions:  [1.2765285316332098, 85.3637172970334, 13.35975417133339]\n"
     ]
    }
   ],
   "source": [
    "count = Counter(y.values())\n",
    "total = sum(count.values())\n",
    "percentage = [val/float(total)*100 for val in count.values()]\n",
    "print 'Percentage of classes in raw data: ', percentage\n",
    "\n",
    "predictions = knn.predict(X.values())\n",
    "count = Counter(predictions)\n",
    "percentage = [val/float(total)*100 for val in count.values()]\n",
    "print 'Percentage of classes in predictions: ', percentage"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "sda",
   "language": "python",
   "name": "sda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
